# -*- coding: utf-8 -*-
"""XGBoostTraining.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XfwouX1zmk5Oro-zplofI_b273dJWpB4
"""

import pandas as pd
import numpy as np
import nltk
import xgboost
import sklearn
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from textPreProcessing import DataProcessor

nltk.download('wordnet')

# Downloads dataset into pandas dataframe
dataframe = pd.read_csv("./Dataset/training.csv",
                        encoding='ISO-8859-1',
                        names=['target','ids','date','flag','user','tweet'])

# Changes the target value for postive from 4 to 1 so it is more compatible with binary classification
dataframe['target'] = np.where(dataframe['target'] == 4, 1, 0)

# Loads the training and test data used by the classifier model
indexes = np.load("./datasetBothModels/indexes.npy")
trainDataframe = dataframe.loc[indexes]
testIndexes = np.load("./datasetBothModels/testIndexes.npy")
testDataframe = dataframe.loc[testIndexes]

# Cleans data and converts it to list
cleaner = DataProcessor()

xTrain = cleaner.CleanTextData(trainDataframe["tweet"]).values.tolist()
yTrain = trainDataframe["target"].values.tolist()

xTest = cleaner.CleanTextData(testDataframe["tweet"]).values.tolist()
yTest = testDataframe["target"].values.tolist()

# Vectorizes the words and converts to xgboost compatible matrices
vectorizer = TfidfVectorizer(max_features=5000)

xTrain = vectorizer.fit_transform(xTrain)
xTrain = xTrain.toarray()

xTest = vectorizer.fit_transform(xTest)
xTest = xTest.toarray()

xTrain = xgboost.DMatrix(xTrain)
xTest = xgboost.DMatrix(xTest)
yTrain = xgboost.DMatrix(np.reshape(yTrain, (100000, 1)))
yTest = xgboost.DMatrix(np.reshape(yTest, (9375, 1)))

# Trains classifier on the data
dataLength = 100000

xgModel = xgboost.XGBClassifier(max_leaves=0, max_depth=6, n_estimators=1000, learning_rate=0.01, objective='binary:logistic')
xgModel.fit(xTrain[:dataLength], yTrain[:dataLength])

# predicts test data values
predictions = xgModel.predict(xTest[:dataLength])

# Calculates accuracy on test data
correct = 0
for i, pred in enumerate(predictions):
  if pred == yTest[i]:
    correct += 1

print(correct / len(predictions))

# Saves model
xgModel.save_model("./models/xgBoostModel4N.txt")

# Loads and evaluates model on test dataset
xgModel = xgboost.Booster()
xgModel.load_model("./models/xgBoostModel4N.txt")

predictions = xgModel.predict(xTest)

clampedPredictions = np.where(predictions > 0.5, predictions, 0)
clampedPredictions = np.where(clampedPredictions <= 0.5, clampedPredictions, 1)

labels = yTest.get_data().data

correct = 0
for i, pred in enumerate(clampedPredictions):
  if pred == labels[i]:
    correct += 1

print(correct / len(predictions))